import pandas as pd
import time
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm 
from prompts.prdInference import DEFAULT_SYSTEM_PROMPT
from util.search import getPrdListByFilter, getPrdListByKeyword, process_es_hit_to_display
from util.product import getProductInfo, analyze_product_with_full_context


# ==============================================================================
# [2] ë©”ì¸ ë³‘ë ¬ ì‹¤í–‰ í•¨ìˆ˜
# ==============================================================================
def extractExcelByPrdList(siteCd, page, pageSize):
    try:
        print("ğŸš€ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì¤‘...")
        list_data = getPrdListByFilter(siteCd=siteCd, page=page, pageSize=pageSize)
        # list_data = getPrdListByKeyword(siteCd="1", keyword=381377039)
        
        # ë°ì´í„° ìœ íš¨ì„± ì²´í¬
        if not list_data or 'data' not in list_data:
            print("âŒ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        hits = list_data['data']['result']['hits']['hits']
        raw_results = [process_es_hit_to_display(hit) for hit in hits]
        total_count = len(raw_results)
        
        print(f"âœ… ì´ {total_count}ê°œì˜ ìƒí’ˆì„ ë¶„ì„í•©ë‹ˆë‹¤. (ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘)")
        
        final_results = []
        
        # 1. ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=50) as executor:
            future_to_prd = {executor.submit(process_single_product, item): item for item in raw_results}
            
            for future in tqdm(as_completed(future_to_prd), total=total_count, desc="AI ë¶„ì„ ì¤‘"):
                try:
                    result = future.result()
                    final_results.append(result)
                except Exception as e:
                    print(f"âŒ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")

        # ==========================================================
        # 2. ë°ì´í„° í›„ì²˜ë¦¬ ë° CSV ì €ì¥ (ìˆ˜ì •ë¨)
        # ==========================================================
        print("\nğŸ’¾ ë°ì´í„° ë³€í™˜ ë° ì €ì¥ ì¤‘...")
        
        csv_rows = []
        for item in final_results:
            # 1) ê¸°ë³¸ ì •ë³´ (ìƒí’ˆë²ˆí˜¸, ìƒíƒœ)
            row = {
                'prdNo': item.get('prdNo'),
                'status': item.get('status')
            }
            
            # 2) AI ë¶„ì„ ë°ì´í„° ë³‘í•©
            if item.get('status') == 'success' and 'data' in item:
                ai_data = item['data']
                
                # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜ (v1: .dict(), v2: .model_dump())
                if hasattr(ai_data, 'model_dump'):
                    ai_dict = ai_data.model_dump()
                elif hasattr(ai_data, 'dict'):
                    ai_dict = ai_data.dict()
                else:
                    ai_dict = ai_data if isinstance(ai_data, dict) else {}

                # ==========================================================
                # â˜… [ì¶”ê°€] ì—‘ì…€ íŠ¹ì • í•„ë“œì— JSON ì›ë³¸ ë¬¸ìì—´ ì €ì¥
                # ==========================================================
                # ensure_ascii=Falseë¥¼ í•´ì•¼ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šê³  ì €ì¥ë©ë‹ˆë‹¤.
                row['jsonObj'] = json.dumps(ai_dict, ensure_ascii=False)    

                # 3) ë°ì´í„° ì •ì œ (ë¦¬ìŠ¤íŠ¸ -> ë¬¸ìì—´ ë³€í™˜)
                for k, v in ai_dict.items():
                    # ë¦¬ìŠ¤íŠ¸ íƒ€ì… (ì˜ˆ: ['ë´„', 'ê°€ì„']) -> ë¬¸ìì—´ ("ë´„, ê°€ì„")
                    if isinstance(v, list):
                        row[k] = "|".join(str(x) for x in v)
                    # None ê°’ -> ë¹ˆ ë¬¸ìì—´
                    elif v is None:
                        row[k] = ""
                    # ê·¸ ì™¸ (ë¬¸ìì—´, ìˆ«ì ë“±)
                    else:
                        row[k] = str(v)
            
            # 4) ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‚¬ìœ  ê¸°ë¡
            elif item.get('status') == 'error':
                row['ì—ëŸ¬ì‚¬ìœ '] = item.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
            
            csv_rows.append(row)

        # 3. DataFrame ìƒì„± ë° ì €ì¥
        if csv_rows:
            # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬ (ë³´ê¸° ì¢‹ê²Œ)
            # ì›í•˜ëŠ” ì»¬ëŸ¼ ìˆœì„œê°€ ìˆë‹¤ë©´ columns=['ìƒí’ˆë²ˆí˜¸', 'ai_category_L', ...] ë¡œ ì§€ì • ê°€ëŠ¥
            df = pd.DataFrame(csv_rows)
            
            # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
            file_name = f"ai_analysis_result_{int(time.time())}.csv"
            
            # CSV ì €ì¥ (utf-8-sig: ì—‘ì…€ í•œê¸€ ê¹¨ì§ ë°©ì§€)
            df.to_csv(file_name, index=False, encoding='utf-8-sig')
            
            print(f"ğŸ‰ ì €ì¥ ì™„ë£Œ! íŒŒì¼ëª…: {file_name}")

        else:
            print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}")


# ==============================================================================
# [1] ë‹¨ì¼ ìƒí’ˆ ì²˜ë¦¬ í•¨ìˆ˜ (Worker)
# ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ forë¬¸ ì•ˆì˜ ë¡œì§ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í–ˆìŠµë‹ˆë‹¤.
# ==============================================================================
def process_single_product(hit):
    try:
        prdNo = hit['prdNo']
        
        # ìƒí’ˆ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        prdInfo = getProductInfo(prdNo)
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if prdInfo is not None and not prdInfo.empty:
            # AI ë¶„ì„ ìˆ˜í–‰
            # (ì£¼ì˜: system_prompt ë³€ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. í•„ìš”ì‹œ import ë˜ëŠ” ì¸ìë¡œ ì „ë‹¬)
            res = analyze_product_with_full_context(
                prdInfo, 
                system_prompt=DEFAULT_SYSTEM_PROMPT
            )
            return {
                "status": "success",
                "prdNo": prdNo,
                "data": res
            }
        else:
            return {
                "status": "skipped",
                "prdNo": prdNo,
                "reason": "ì •ë³´ ì—†ìŒ"
            }
            
    except Exception as e:
        return {
            "status": "error",
            "prdNo": hit.get('prdNo', 'unknown'),
            "error": str(e)
        }
            



        
        

    

